{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 100\n",
    "test_batch_size = 10000\n",
    "epoch_num = 10\n",
    "lr = 0.2\n",
    "seed = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "2.5.1\n",
      "12.4\n",
      "True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "print(\"Using device:\", device)\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)              # Should not be None\n",
    "print(torch.cuda.is_available())       # Should be True if everything is correct\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(size=32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transformation\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_dataset_fast = CIFAR10(root='./data', train=True, download=True,\n",
    "    transform=transformation\n",
    ")\n",
    "\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=4)\n",
    "\n",
    "train_loader_fast = DataLoader(train_dataset_fast, batch_size=1000, shuffle=True,\n",
    "    num_workers=4)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 5, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(5, 5, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(125, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 | Train Loss: 1.9268\n",
      "Epoch 2/2 | Train Loss: 1.6882\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "num_epochs = 2\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {running_loss/len(train_loader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian(model, loss):\n",
    "    grad = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "    flattened_grad = torch.cat([g.reshape(-1) for g in grad])\n",
    "\n",
    "    hessian = []\n",
    "\n",
    "    for g in flattened_grad:\n",
    "        hessian_g = torch.autograd.grad(g, model.parameters(), retain_graph=True)\n",
    "        flattened_hessian_g = torch.cat([h.reshape(-1) for h in hessian_g])\n",
    "        hessian.append(flattened_hessian_g)\n",
    "\n",
    "    return torch.stack(hessian)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try torch.autograd.functional.hessian\n",
    "\n",
    "Doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Hessian Start [via torch.autograd.functional.hessian]\n",
      "Calculating Hessian End [via torch.autograd.functional.hessian]\n",
      "Smallest 5 eigenvalues:  tensor([0., 0., 0., 0., 0.], device='cuda:0')\n",
      "Largest 5 eigenvalues:  tensor([0., 0., 0., 0., 0.], device='cuda:0')\n",
      "Smoothness (largest absolute value of eigenvalues):  tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "model.train()\n",
    "images, labels = next(iter(train_loader_fast))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "\n",
    "def loss_fn(params):\n",
    "    # Reconstruct the model.parameters() to a 1D array) for the loss\n",
    "    param_idx = 0  # Track position in the 1D params tensor\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        numel = p.numel()  # Get number of elements in the current parameter\n",
    "        p.data = params[param_idx : param_idx + numel].view_as(p).data  # Reshape and assign\n",
    "        param_idx += numel  # Move index forward\n",
    "\n",
    "    outputs = model(images)  # Forward pass\n",
    "    return criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "params = torch.cat([p.view(-1) for p in model.parameters()])\n",
    "print('Calculating Hessian Start [via torch.autograd.functional.hessian]')\n",
    "hessian = torch.autograd.functional.hessian(loss_fn, params)\n",
    "print('Calculating Hessian End [via torch.autograd.functional.hessian]')\n",
    "\n",
    "eigval = torch.linalg.eigvalsh(hessian)\n",
    "small_eigval = eigval[:5]\n",
    "big_eigval = eigval[-5:]\n",
    "smoothness = torch.max(torch.abs(eigval))\n",
    "\n",
    "print(\"Smallest 5 eigenvalues: \", small_eigval)\n",
    "print(\"Largest 5 eigenvalues: \", big_eigval)\n",
    "print(\"Smoothness (largest absolute value of eigenvalues): \", smoothness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try DIY Hessain Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Hessian Start [via DIY function]\n",
      "Calculating Hessian End [via DIY function]\n",
      "Smallest 5 eigenvalues:  tensor([-1.3055, -1.1555, -0.9420, -0.8477, -0.8134], device='cuda:0')\n",
      "Largest 5 eigenvalues:  tensor([17.5356, 18.0376, 22.0060, 29.3952, 43.8828], device='cuda:0')\n",
      "Smoothness (largest absolute value of eigenvalues):  tensor(43.8828, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "images, labels = next(iter(train_loader_fast))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "print('Calculating Hessian Start [via DIY function]')\n",
    "hessian = compute_hessian(model, loss)\n",
    "print('Calculating Hessian End [via DIY function]')\n",
    "\n",
    "eigval = torch.linalg.eigvalsh(hessian)\n",
    "small_eigval = eigval[:5]\n",
    "big_eigval = eigval[-5:]\n",
    "smoothness = torch.max(torch.abs(eigval))\n",
    "\n",
    "print(\"Smallest 5 eigenvalues: \", small_eigval)\n",
    "print(\"Largest 5 eigenvalues: \", big_eigval)\n",
    "print(\"Smoothness (largest absolute value of eigenvalues): \", smoothness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 HVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_vector_product(model, criterion, images, labels, v):\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    grad = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "    flattened_grad = torch.cat([g.view(-1) for g in grad])\n",
    "\n",
    "    # gv = flattened_grad @ v\n",
    "\n",
    "    hv = torch.autograd.grad(flattened_grad, model.parameters(), grad_outputs=v, retain_graph=False)\n",
    "    \n",
    "    return torch.cat([h.reshape(-1) for h in hv])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda_0 = 0.04943562671542168\n",
      "lamda_1 = 17.987499237060547\n",
      "lamda_2 = 34.403419494628906\n",
      "lamda_3 = 43.2529411315918\n",
      "lamda_4 = 41.97267150878906\n",
      "lamda_5 = 47.71524429321289\n",
      "lamda_6 = 44.2011604309082\n",
      "lamda_7 = 43.06145477294922\n",
      "lamda_8 = 44.172874450683594\n",
      "lamda_9 = 44.66304016113281\n",
      "lamda_10 = 44.983062744140625\n",
      "lamda_11 = 51.16176223754883\n",
      "lamda_12 = 48.02653884887695\n",
      "lamda_13 = 46.00290298461914\n",
      "lamda_14 = 42.938636779785156\n",
      "lamda_15 = 47.85685729980469\n",
      "lamda_16 = 44.14205551147461\n",
      "lamda_17 = 43.55768585205078\n",
      "lamda_18 = 46.36376190185547\n",
      "lamda_19 = 43.89331817626953\n",
      "lamda_20 = 44.943477630615234\n",
      "lamda_21 = 49.79100799560547\n",
      "lamda_22 = 41.97179412841797\n",
      "lamda_23 = 48.928672790527344\n",
      "lamda_24 = 44.84471893310547\n",
      "lamda_25 = 41.98912048339844\n",
      "lamda_26 = 44.790489196777344\n",
      "lamda_27 = 44.08843231201172\n",
      "lamda_28 = 47.47641372680664\n",
      "lamda_29 = 47.21642303466797\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "d = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "v = torch.randn(d, device=device)\n",
    "v = F.normalize(v, p=2, dim=0)\n",
    "\n",
    "max_iters = 30\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader_fast):\n",
    "    if i >= max_iters:\n",
    "        break \n",
    "    # images, labels = next(iter(train_loader_fast))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    hv = hessian_vector_product(model, criterion, images, labels, v)\n",
    "    lambda_k = v @ hv\n",
    "    v = F.normalize(hv, p=2, dim=0)\n",
    "    print(f'lamda_{i} = {lambda_k}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Result above is not stable since we are using different minibatch. The Hessian Computed directly above is using data from one minibatch. Here we are trying to approximate the actual hessian across different minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With acceleration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda_0 = 0.04608114808797836\n",
      "lamda_1 = 0.6441468000411987\n",
      "lamda_2 = 2.113363265991211\n",
      "lamda_3 = 4.504873752593994\n",
      "lamda_4 = 7.472621917724609\n",
      "lamda_5 = 10.638004302978516\n",
      "lamda_6 = 14.062822341918945\n",
      "lamda_7 = 18.413776397705078\n",
      "lamda_8 = 22.378620147705078\n",
      "lamda_9 = 23.377376556396484\n",
      "lamda_10 = 29.914936065673828\n",
      "lamda_11 = 29.294254302978516\n",
      "lamda_12 = 32.178897857666016\n",
      "lamda_13 = 33.120391845703125\n",
      "lamda_14 = 35.00140380859375\n",
      "lamda_15 = 42.59052658081055\n",
      "lamda_16 = 38.71431350708008\n",
      "lamda_17 = 40.72813415527344\n",
      "lamda_18 = 43.86983871459961\n",
      "lamda_19 = 42.07209014892578\n",
      "lamda_20 = 40.213172912597656\n",
      "lamda_21 = 45.33381652832031\n",
      "lamda_22 = 43.199344635009766\n",
      "lamda_23 = 43.30857849121094\n",
      "lamda_24 = 45.44932556152344\n",
      "lamda_25 = 41.69606018066406\n",
      "lamda_26 = 46.18921661376953\n",
      "lamda_27 = 42.7132568359375\n",
      "lamda_28 = 43.35588455200195\n",
      "lamda_29 = 41.27893829345703\n",
      "lamda_30 = 44.70640563964844\n",
      "lamda_31 = 48.74162292480469\n",
      "lamda_32 = 41.39077377319336\n",
      "lamda_33 = 43.6795654296875\n",
      "lamda_34 = 46.233551025390625\n",
      "lamda_35 = 41.79230880737305\n",
      "lamda_36 = 42.721221923828125\n",
      "lamda_37 = 45.79912185668945\n",
      "lamda_38 = 44.20038604736328\n",
      "lamda_39 = 47.08355712890625\n",
      "lamda_40 = 44.03317642211914\n",
      "lamda_41 = 45.31916427612305\n",
      "lamda_42 = 45.37019348144531\n",
      "lamda_43 = 41.60755157470703\n",
      "lamda_44 = 50.0418701171875\n",
      "lamda_45 = 45.59941864013672\n",
      "lamda_46 = 48.03764343261719\n",
      "lamda_47 = 45.55094909667969\n",
      "lamda_48 = 45.96278381347656\n",
      "lamda_49 = 44.122833251953125\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "beta = 0.9\n",
    "\n",
    "model.eval()\n",
    "\n",
    "d = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\n",
    "v = torch.randn(d, device=device)\n",
    "v = F.normalize(v, p=2, dim=0)\n",
    "\n",
    "v_prev = v.clone()\n",
    "\n",
    "max_iters = 100\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader_fast):\n",
    "    if i >= max_iters:\n",
    "        break \n",
    "\n",
    "    # images, labels = next(iter(train_loader_fast))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    hv = hessian_vector_product(model, criterion, images, labels, v)\n",
    "    lambda_k = v @ hv\n",
    "    w = F.normalize(hv, p=2, dim=0)\n",
    "    v = beta * v_prev + (1 - beta) * w\n",
    "    v = F.normalize(v, p=2, dim=0)\n",
    "    v_prev = v.clone()\n",
    "    print(f'lamda_{i} = {lambda_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding the acceleration, it is more stable. But still shaking around 45. I think the true max eigenvalue should be set around 45."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 RESNET 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "res50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "res50.fc = nn.Linear(2048, 10)\n",
    "res50 = res50.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(res50.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Training, run 50 iter HPV to find current largest eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda_0 = 0.000440148520283401\n",
      "lamda_1 = 3.352783441543579\n",
      "lamda_2 = 17.269290924072266\n",
      "lamda_3 = 40.06093215942383\n",
      "lamda_4 = 56.9256477355957\n",
      "lamda_5 = 75.51548767089844\n",
      "lamda_6 = 89.07769775390625\n",
      "lamda_7 = 91.07374572753906\n",
      "lamda_8 = 102.65342712402344\n",
      "lamda_9 = 105.86251831054688\n",
      "lamda_10 = 110.94886779785156\n",
      "lamda_11 = 119.92045593261719\n",
      "lamda_12 = 110.92315673828125\n",
      "lamda_13 = 120.11367797851562\n",
      "lamda_14 = 117.76911163330078\n",
      "lamda_15 = 130.5001678466797\n",
      "lamda_16 = 125.642578125\n",
      "lamda_17 = 133.51815795898438\n",
      "lamda_18 = 139.22418212890625\n",
      "lamda_19 = 138.70111083984375\n",
      "lamda_20 = 128.70687866210938\n",
      "lamda_21 = 140.86239624023438\n",
      "lamda_22 = 142.3839111328125\n",
      "lamda_23 = 134.17550659179688\n",
      "lamda_24 = 138.90469360351562\n",
      "lamda_25 = 129.22598266601562\n",
      "lamda_26 = 131.9697265625\n",
      "lamda_27 = 135.31312561035156\n",
      "lamda_28 = 128.69544982910156\n",
      "lamda_29 = 134.53318786621094\n",
      "lamda_30 = 129.28634643554688\n",
      "lamda_31 = 145.08905029296875\n",
      "lamda_32 = 142.05050659179688\n",
      "lamda_33 = 137.40682983398438\n",
      "lamda_34 = 142.4477996826172\n",
      "lamda_35 = 147.0555419921875\n",
      "lamda_36 = 147.925048828125\n",
      "lamda_37 = 135.99801635742188\n",
      "lamda_38 = 149.00469970703125\n",
      "lamda_39 = 136.66993713378906\n",
      "lamda_40 = 137.3975830078125\n",
      "lamda_41 = 137.94100952148438\n",
      "lamda_42 = 143.22427368164062\n",
      "lamda_43 = 144.1083526611328\n",
      "lamda_44 = 134.25173950195312\n",
      "lamda_45 = 144.00491333007812\n",
      "lamda_46 = 153.83029174804688\n",
      "lamda_47 = 149.52914428710938\n",
      "lamda_48 = 141.6023712158203\n",
      "lamda_49 = 144.0352783203125\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "beta = 0.7\n",
    "\n",
    "res50.eval()\n",
    "\n",
    "d = sum(p.numel() for p in res50.parameters())\n",
    "\n",
    "\n",
    "v = torch.randn(d, device=device)\n",
    "v = F.normalize(v, p=2, dim=0)\n",
    "\n",
    "v_prev = v.clone()\n",
    "\n",
    "max_iters = 100\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader_fast):\n",
    "    if i >= max_iters:\n",
    "        break \n",
    "\n",
    "    # images, labels = next(iter(train_loader_fast))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    hv = hessian_vector_product(res50, criterion, images, labels, v)\n",
    "    lambda_k = v @ hv\n",
    "    w = F.normalize(hv, p=2, dim=0)\n",
    "    v = beta * v_prev + (1 - beta) * w\n",
    "    v = F.normalize(v, p=2, dim=0)\n",
    "    v_prev = v.clone()\n",
    "    print(f'lamda_{i} = {lambda_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Training, the max eigenvalue is about 140-150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train for 10 Epochs (with SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.7064 | Train ACC 37.4520\n",
      "Epoch 2/10 | Train Loss: 1.2523 | Train ACC 56.1740\n",
      "Epoch 3/10 | Train Loss: 1.0304 | Train ACC 64.7760\n",
      "Epoch 4/10 | Train Loss: 0.9372 | Train ACC 68.1960\n",
      "Epoch 5/10 | Train Loss: 0.8725 | Train ACC 70.4100\n",
      "Epoch 6/10 | Train Loss: 0.8524 | Train ACC 71.1720\n",
      "Epoch 7/10 | Train Loss: 0.8318 | Train ACC 71.9320\n",
      "Epoch 8/10 | Train Loss: 0.8180 | Train ACC 72.5040\n",
      "Epoch 9/10 | Train Loss: 0.8120 | Train ACC 72.6020\n",
      "Epoch 10/10 | Train Loss: 0.8105 | Train ACC 72.8640\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "res50.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = res50(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {running_loss/len(train_loader):.4f} | Train ACC {correct/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda_0 = 5.1203918701503426e-05\n",
      "lamda_1 = 10.533380508422852\n",
      "lamda_2 = 33.889408111572266\n",
      "lamda_3 = 57.487884521484375\n",
      "lamda_4 = 78.51637268066406\n",
      "lamda_5 = 78.56939697265625\n",
      "lamda_6 = 82.51615905761719\n",
      "lamda_7 = 89.28289794921875\n",
      "lamda_8 = 78.9213638305664\n",
      "lamda_9 = 90.4259262084961\n",
      "lamda_10 = 93.57878112792969\n",
      "lamda_11 = 88.91712951660156\n",
      "lamda_12 = 85.32963562011719\n",
      "lamda_13 = 90.96769714355469\n",
      "lamda_14 = 89.72052001953125\n",
      "lamda_15 = 83.48465728759766\n",
      "lamda_16 = 90.65206146240234\n",
      "lamda_17 = 86.23033142089844\n",
      "lamda_18 = 93.91207122802734\n",
      "lamda_19 = 92.53163146972656\n",
      "lamda_20 = 93.11539459228516\n",
      "lamda_21 = 89.27662658691406\n",
      "lamda_22 = 84.85992431640625\n",
      "lamda_23 = 84.87395477294922\n",
      "lamda_24 = 91.73284912109375\n",
      "lamda_25 = 88.80448150634766\n",
      "lamda_26 = 84.22303009033203\n",
      "lamda_27 = 86.10324096679688\n",
      "lamda_28 = 94.76228332519531\n",
      "lamda_29 = 92.35308074951172\n",
      "lamda_30 = 90.03672790527344\n",
      "lamda_31 = 101.22908782958984\n",
      "lamda_32 = 88.31964874267578\n",
      "lamda_33 = 89.49870300292969\n",
      "lamda_34 = 92.96106719970703\n",
      "lamda_35 = 86.28799438476562\n",
      "lamda_36 = 90.7708511352539\n",
      "lamda_37 = 84.66935729980469\n",
      "lamda_38 = 87.57194519042969\n",
      "lamda_39 = 78.18917846679688\n",
      "lamda_40 = 83.83026885986328\n",
      "lamda_41 = 88.5374755859375\n",
      "lamda_42 = 85.39281463623047\n",
      "lamda_43 = 89.046875\n",
      "lamda_44 = 92.79761505126953\n",
      "lamda_45 = 81.40123748779297\n",
      "lamda_46 = 84.89994049072266\n",
      "lamda_47 = 88.1558837890625\n",
      "lamda_48 = 91.8496322631836\n",
      "lamda_49 = 84.00738525390625\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "beta = 0.7\n",
    "\n",
    "res50.eval()\n",
    "\n",
    "d = sum(p.numel() for p in res50.parameters())\n",
    "\n",
    "\n",
    "v = torch.randn(d, device=device)\n",
    "v = F.normalize(v, p=2, dim=0)\n",
    "\n",
    "v_prev = v.clone()\n",
    "\n",
    "max_iters = 100\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader_fast):\n",
    "    if i >= max_iters:\n",
    "        break \n",
    "\n",
    "    # images, labels = next(iter(train_loader_fast))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    hv = hessian_vector_product(res50, criterion, images, labels, v)\n",
    "    lambda_k = v @ hv\n",
    "    w = F.normalize(hv, p=2, dim=0)\n",
    "    v = beta * v_prev + (1 - beta) * w\n",
    "    v = F.normalize(v, p=2, dim=0)\n",
    "    v_prev = v.clone()\n",
    "    print(f'lamda_{i} = {lambda_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the largest eigenvalue is about 85 - 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train for Another 90 Epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90 | Train Loss: 0.8119 | Train ACC 72.7020\n",
      "Epoch 2/90 | Train Loss: 0.8039 | Train ACC 72.7060\n",
      "Epoch 3/90 | Train Loss: 0.7974 | Train ACC 72.9300\n",
      "Epoch 4/90 | Train Loss: 0.8000 | Train ACC 72.8840\n",
      "Epoch 5/90 | Train Loss: 0.7996 | Train ACC 73.0760\n",
      "Epoch 6/90 | Train Loss: 0.7895 | Train ACC 73.4100\n",
      "Epoch 7/90 | Train Loss: 0.7857 | Train ACC 73.5040\n",
      "Epoch 8/90 | Train Loss: 0.7874 | Train ACC 73.6060\n",
      "Epoch 9/90 | Train Loss: 0.7841 | Train ACC 73.3660\n",
      "Epoch 10/90 | Train Loss: 0.7761 | Train ACC 73.8440\n",
      "Epoch 11/90 | Train Loss: 0.7653 | Train ACC 74.2760\n",
      "Epoch 12/90 | Train Loss: 0.7743 | Train ACC 73.8640\n",
      "Epoch 13/90 | Train Loss: 0.7706 | Train ACC 74.0900\n",
      "Epoch 14/90 | Train Loss: 0.7728 | Train ACC 74.0140\n",
      "Epoch 15/90 | Train Loss: 0.7684 | Train ACC 74.1700\n",
      "Epoch 16/90 | Train Loss: 0.7644 | Train ACC 74.3360\n",
      "Epoch 17/90 | Train Loss: 0.7599 | Train ACC 74.4760\n",
      "Epoch 18/90 | Train Loss: 0.7609 | Train ACC 74.3200\n",
      "Epoch 19/90 | Train Loss: 0.7590 | Train ACC 74.4960\n",
      "Epoch 20/90 | Train Loss: 0.7534 | Train ACC 74.3800\n",
      "Epoch 21/90 | Train Loss: 0.7511 | Train ACC 74.7920\n",
      "Epoch 22/90 | Train Loss: 0.7510 | Train ACC 74.6440\n",
      "Epoch 23/90 | Train Loss: 0.7458 | Train ACC 74.9680\n",
      "Epoch 24/90 | Train Loss: 0.7511 | Train ACC 74.8280\n",
      "Epoch 25/90 | Train Loss: 0.7556 | Train ACC 74.4360\n",
      "Epoch 26/90 | Train Loss: 0.7526 | Train ACC 74.4480\n",
      "Epoch 27/90 | Train Loss: 0.7461 | Train ACC 74.8020\n",
      "Epoch 28/90 | Train Loss: 0.7586 | Train ACC 74.2620\n",
      "Epoch 29/90 | Train Loss: 0.7397 | Train ACC 74.9960\n",
      "Epoch 30/90 | Train Loss: 0.7435 | Train ACC 75.0320\n",
      "Epoch 31/90 | Train Loss: 0.7424 | Train ACC 74.8560\n",
      "Epoch 32/90 | Train Loss: 0.7564 | Train ACC 74.7000\n",
      "Epoch 33/90 | Train Loss: 0.7424 | Train ACC 74.7680\n",
      "Epoch 34/90 | Train Loss: 0.7420 | Train ACC 75.1140\n",
      "Epoch 35/90 | Train Loss: 0.7460 | Train ACC 74.8400\n",
      "Epoch 36/90 | Train Loss: 0.7427 | Train ACC 74.9680\n",
      "Epoch 37/90 | Train Loss: 0.7393 | Train ACC 75.1340\n",
      "Epoch 38/90 | Train Loss: 0.7367 | Train ACC 75.2140\n",
      "Epoch 39/90 | Train Loss: 0.7398 | Train ACC 75.1060\n",
      "Epoch 40/90 | Train Loss: 0.7325 | Train ACC 75.1940\n",
      "Epoch 41/90 | Train Loss: 0.7419 | Train ACC 75.0220\n",
      "Epoch 42/90 | Train Loss: 0.7302 | Train ACC 75.6260\n",
      "Epoch 43/90 | Train Loss: 0.7379 | Train ACC 74.9780\n",
      "Epoch 44/90 | Train Loss: 0.7390 | Train ACC 75.0700\n",
      "Epoch 45/90 | Train Loss: 0.7383 | Train ACC 75.0380\n",
      "Epoch 46/90 | Train Loss: 0.7312 | Train ACC 75.3160\n",
      "Epoch 47/90 | Train Loss: 0.7378 | Train ACC 75.0500\n",
      "Epoch 48/90 | Train Loss: 0.7319 | Train ACC 75.5480\n",
      "Epoch 49/90 | Train Loss: 0.7309 | Train ACC 75.3040\n",
      "Epoch 50/90 | Train Loss: 0.7304 | Train ACC 75.4680\n",
      "Epoch 51/90 | Train Loss: 0.7328 | Train ACC 75.3940\n",
      "Epoch 52/90 | Train Loss: 0.7323 | Train ACC 75.1980\n",
      "Epoch 53/90 | Train Loss: 0.7255 | Train ACC 75.5120\n",
      "Epoch 54/90 | Train Loss: 0.7374 | Train ACC 75.1700\n",
      "Epoch 55/90 | Train Loss: 0.7249 | Train ACC 75.7160\n",
      "Epoch 56/90 | Train Loss: 0.7211 | Train ACC 75.5980\n",
      "Epoch 57/90 | Train Loss: 0.7332 | Train ACC 75.3420\n",
      "Epoch 58/90 | Train Loss: 0.7285 | Train ACC 75.5100\n",
      "Epoch 59/90 | Train Loss: 0.7256 | Train ACC 75.5860\n",
      "Epoch 60/90 | Train Loss: 0.7283 | Train ACC 75.4480\n",
      "Epoch 61/90 | Train Loss: 0.7217 | Train ACC 75.7500\n",
      "Epoch 62/90 | Train Loss: 0.7311 | Train ACC 75.1380\n",
      "Epoch 63/90 | Train Loss: 0.7277 | Train ACC 75.2840\n",
      "Epoch 64/90 | Train Loss: 0.7318 | Train ACC 75.2100\n",
      "Epoch 65/90 | Train Loss: 0.7277 | Train ACC 75.5860\n",
      "Epoch 66/90 | Train Loss: 0.7250 | Train ACC 75.4640\n",
      "Epoch 67/90 | Train Loss: 0.7249 | Train ACC 75.4520\n",
      "Epoch 68/90 | Train Loss: 0.7293 | Train ACC 75.3660\n",
      "Epoch 69/90 | Train Loss: 0.7261 | Train ACC 75.5400\n",
      "Epoch 70/90 | Train Loss: 0.7278 | Train ACC 75.4320\n",
      "Epoch 71/90 | Train Loss: 0.7281 | Train ACC 75.4680\n",
      "Epoch 72/90 | Train Loss: 0.7251 | Train ACC 75.3900\n",
      "Epoch 73/90 | Train Loss: 0.7237 | Train ACC 75.5660\n",
      "Epoch 74/90 | Train Loss: 0.7180 | Train ACC 75.6980\n",
      "Epoch 75/90 | Train Loss: 0.7310 | Train ACC 75.4200\n",
      "Epoch 76/90 | Train Loss: 0.7265 | Train ACC 75.3600\n",
      "Epoch 77/90 | Train Loss: 0.7244 | Train ACC 75.6040\n",
      "Epoch 78/90 | Train Loss: 0.7286 | Train ACC 75.4880\n",
      "Epoch 79/90 | Train Loss: 0.7235 | Train ACC 75.5480\n",
      "Epoch 80/90 | Train Loss: 0.7295 | Train ACC 75.2380\n",
      "Epoch 81/90 | Train Loss: 0.7224 | Train ACC 75.5340\n",
      "Epoch 82/90 | Train Loss: 0.7194 | Train ACC 75.4520\n",
      "Epoch 83/90 | Train Loss: 0.7322 | Train ACC 75.2540\n",
      "Epoch 84/90 | Train Loss: 0.7216 | Train ACC 75.7740\n",
      "Epoch 85/90 | Train Loss: 0.7279 | Train ACC 75.4800\n",
      "Epoch 86/90 | Train Loss: 0.7190 | Train ACC 75.6340\n",
      "Epoch 87/90 | Train Loss: 0.7253 | Train ACC 75.7280\n",
      "Epoch 88/90 | Train Loss: 0.7241 | Train ACC 75.5660\n",
      "Epoch 89/90 | Train Loss: 0.7200 | Train ACC 75.6600\n",
      "Epoch 90/90 | Train Loss: 0.7183 | Train ACC 75.9380\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 90\n",
    "\n",
    "res50.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = res50(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} | Train Loss: {running_loss/len(train_loader):.4f} | Train ACC {correct/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamda_0 = 1.2004034033452626e-05\n",
      "lamda_1 = 2.223109722137451\n",
      "lamda_2 = 14.219112396240234\n",
      "lamda_3 = 29.89647102355957\n",
      "lamda_4 = 42.67970657348633\n",
      "lamda_5 = 49.205081939697266\n",
      "lamda_6 = 53.42639923095703\n",
      "lamda_7 = 55.85221862792969\n",
      "lamda_8 = 57.554874420166016\n",
      "lamda_9 = 47.59864044189453\n",
      "lamda_10 = 60.894447326660156\n",
      "lamda_11 = 56.13178253173828\n",
      "lamda_12 = 55.43880081176758\n",
      "lamda_13 = 63.29621124267578\n",
      "lamda_14 = 56.31103515625\n",
      "lamda_15 = 57.8975830078125\n",
      "lamda_16 = 57.65886306762695\n",
      "lamda_17 = 53.80331802368164\n",
      "lamda_18 = 57.59252166748047\n",
      "lamda_19 = 56.668182373046875\n",
      "lamda_20 = 60.59246826171875\n",
      "lamda_21 = 62.371795654296875\n",
      "lamda_22 = 60.13347244262695\n",
      "lamda_23 = 51.59734344482422\n",
      "lamda_24 = 55.82365417480469\n",
      "lamda_25 = 55.86796951293945\n",
      "lamda_26 = 59.20222091674805\n",
      "lamda_27 = 58.959434509277344\n",
      "lamda_28 = 59.363983154296875\n",
      "lamda_29 = 54.76301574707031\n",
      "lamda_30 = 56.89745330810547\n",
      "lamda_31 = 59.04413986206055\n",
      "lamda_32 = 55.65510177612305\n",
      "lamda_33 = 63.013431549072266\n",
      "lamda_34 = 58.13995361328125\n",
      "lamda_35 = 59.34771728515625\n",
      "lamda_36 = 63.52116775512695\n",
      "lamda_37 = 56.872833251953125\n",
      "lamda_38 = 57.176151275634766\n",
      "lamda_39 = 61.99126434326172\n",
      "lamda_40 = 57.62110900878906\n",
      "lamda_41 = 58.472564697265625\n",
      "lamda_42 = 62.63465118408203\n",
      "lamda_43 = 59.14935302734375\n",
      "lamda_44 = 60.12319564819336\n",
      "lamda_45 = 64.32384490966797\n",
      "lamda_46 = 53.23441696166992\n",
      "lamda_47 = 52.654212951660156\n",
      "lamda_48 = 60.20011901855469\n",
      "lamda_49 = 61.967041015625\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "beta = 0.7\n",
    "\n",
    "res50.eval()\n",
    "\n",
    "d = sum(p.numel() for p in res50.parameters())\n",
    "\n",
    "\n",
    "v = torch.randn(d, device=device)\n",
    "v = F.normalize(v, p=2, dim=0)\n",
    "\n",
    "v_prev = v.clone()\n",
    "\n",
    "max_iters = 100\n",
    "\n",
    "for i, (images, labels) in enumerate(train_loader_fast):\n",
    "    if i >= max_iters:\n",
    "        break \n",
    "\n",
    "    # images, labels = next(iter(train_loader_fast))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    hv = hessian_vector_product(res50, criterion, images, labels, v)\n",
    "    lambda_k = v @ hv\n",
    "    w = F.normalize(hv, p=2, dim=0)\n",
    "    v = beta * v_prev + (1 - beta) * w\n",
    "    v = F.normalize(v, p=2, dim=0)\n",
    "    v_prev = v.clone()\n",
    "    print(f'lamda_{i} = {lambda_k}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Largest Eigenvalue is about 60 after 100 epoch training.\n",
    "\n",
    "Note the loss function improved only slightly from 0.81 to 0.71 during the last 90 epoches using SGD. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
